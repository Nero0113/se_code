{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nero0113/se_code/blob/main/re_codebert.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UtFrA6eH3m42",
        "outputId": "faa437f2-b6e9-49d9-c91d-f9abaf565deb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.21.1)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.12.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.12.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.8.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.6.15)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qwacOFDaYWD9",
        "outputId": "2e026a8e-085a-49d4-bbab-2ba90bf6b1e2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorboardX in /usr/local/lib/python3.7/dist-packages (2.5.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from tensorboardX) (1.21.6)\n",
            "Requirement already satisfied: protobuf<=3.20.1,>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorboardX) (3.17.3)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf<=3.20.1,>=3.8.0->tensorboardX) (1.15.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorboardX"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TZWp4tDp34xK",
        "outputId": "7570fda1-4681-4fdd-b6a2-e61a83ca8020"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fri Aug  5 06:39:56 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   44C    P0    29W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6m3YPiln8gv1"
      },
      "source": [
        "处理数据，生成codebert输入"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qAAIlyCCADhT"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "import numpy as np\n",
        "from more_itertools import chunked\n",
        "import random\n",
        "import logging\n",
        "from tqdm import tqdm, trange\n",
        "logger = logging.getLogger(__name__)\n",
        "from tensorboardX import SummaryWriter\n",
        "DATA_DIR = '/content/drive/MyDrive/myclab/codebert/data'\n",
        "def format_str(string):\n",
        "  for char in ['\\r\\n', '\\r', '\\n', '\\t']:\n",
        "    string = string.replace(char, ' ')\n",
        "  return string\n",
        "\n",
        "def _truncate_seq_pair(tokens_a, tokens_b, max_length):\n",
        "    \"\"\"Truncates a sequence pair in place to the maximum length.\"\"\"\n",
        "\n",
        "    # This is a simple heuristic which will always truncate the longer sequence\n",
        "    # one token at a time. This makes more sense than truncating an equal percent\n",
        "    # of tokens from each, since if one sequence is very short then each token\n",
        "    # that's truncated likely contains more information than a longer sequence.\n",
        "    while True:\n",
        "        total_length = len(tokens_a) + len(tokens_b)\n",
        "        if total_length <= max_length:\n",
        "            break\n",
        "        if len(tokens_a) > len(tokens_b):\n",
        "            tokens_a.pop()\n",
        "        else:\n",
        "            tokens_b.pop()\n",
        "\n",
        "class InputFeatures(object):\n",
        "    \"\"\"A single set of features of data.\"\"\"\n",
        "\n",
        "    def __init__(self, input_ids, input_mask, segment_ids, label_id):\n",
        "        self.input_ids = input_ids\n",
        "        self.input_mask = input_mask\n",
        "        self.segment_ids = segment_ids\n",
        "        self.label_id = label_id\n",
        "\n",
        "class DataProcessor(object):\n",
        "  \"\"\"A single training/test example for simple sequence classification.\"\"\"\n",
        "  def __init__(self, pos_data, neg_data):\n",
        "\n",
        "    self.pos_data = pos_data\n",
        "    self.neg_data = neg_data\n",
        "\n",
        "  def get_labels(self):\n",
        "\n",
        "    return [\"0\", \"1\"]\n",
        "\n",
        "  def get_train(self):\n",
        "    # print(\"start get train\")\n",
        "    pos_len = len(self.pos_data)\n",
        "    neg_len = len(self.neg_data)\n",
        "    train_data = []\n",
        "    for i in range(int(pos_len /100 * 70)):\n",
        "      train_data.append(self.pos_data[i])\n",
        "      train_data.append(self.neg_data[i])\n",
        "    return train_data\n",
        "\n",
        "  def get_val(self):\n",
        "    # print(\"start get val\")\n",
        "    pos_len = len(self.pos_data)\n",
        "    neg_len = len(self.neg_data)\n",
        "    val_data = []\n",
        "    val_data += self.pos_data[int(pos_len /100 * 70):int(pos_len /100 * 85)]\n",
        "    val_data += self.neg_data[int(neg_len /100 * 70):int(neg_len /100 * 85)]\n",
        "    return val_data\n",
        "\n",
        "  def get_test(self):\n",
        "    # print(\"start get test\")\n",
        "    pos_len = len(self.pos_data)\n",
        "    neg_len = len(self.neg_data)\n",
        "    test_data = []\n",
        "    test_data += self.pos_data[int(pos_len /100 * 85):]\n",
        "    test_data += self.neg_data[int(neg_len /100 * 85):]\n",
        "    return test_data, test_data\n",
        "\n",
        "  def convert_to_feature(self, examples, max_seq_len, tokenizer,\n",
        "                        cls_token_at_end = False, pad_on_left = False, cls_token = '[CLS]',\n",
        "                        sep_token = '[SEP]', pad_token = 0, sequence_a_segment_id=0,\n",
        "                        sequence_b_segment_id=1,cls_token_segment_id=1, pad_token_segment_id=0,\n",
        "                        mask_padding_with_zero=True):\n",
        "    label_list = [\"0\", \"1\"]\n",
        "    label_map = {label: i for i, label in enumerate(label_list)}\n",
        "\n",
        "    features = []\n",
        "    print(\"start convert to feature\")\n",
        "    for (ex_index, example) in enumerate(tqdm(examples)):\n",
        "        if ex_index % 10000 == 0:\n",
        "            logger.info(\"Writing example %d of %d\" % (ex_index, len(examples)))\n",
        "\n",
        "        tokens_a = tokenizer.tokenize(example['javadoc'])[:50]\n",
        "\n",
        "        tokens_b = None\n",
        "        if example['source']:\n",
        "            tokens_b = tokenizer.tokenize(example['source'])\n",
        "            _truncate_seq_pair(tokens_a, tokens_b, max_seq_len - 3)\n",
        "        else:\n",
        "            # Account for [CLS] and [SEP] with \"- 2\"\n",
        "            if len(tokens_a) > max_seq_len - 2:\n",
        "                tokens_a = tokens_a[:(max_seq_len - 2)]\n",
        "        tokens = tokens_a + [sep_token]\n",
        "        segment_ids = [sequence_a_segment_id] * len(tokens)\n",
        "\n",
        "        if tokens_b:\n",
        "            tokens += tokens_b + [sep_token]\n",
        "            segment_ids += [sequence_b_segment_id] * (len(tokens_b) + 1)\n",
        "\n",
        "        if cls_token_at_end:\n",
        "            tokens = tokens + [cls_token]\n",
        "            segment_ids = segment_ids + [cls_token_segment_id]\n",
        "        else:\n",
        "            tokens = [cls_token] + tokens\n",
        "            segment_ids = [cls_token_segment_id] + segment_ids\n",
        "\n",
        "        input_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
        "\n",
        "        input_mask = [1 if mask_padding_with_zero else 0] * len(input_ids)\n",
        "        padding_length = max_seq_len - len(input_ids)\n",
        "\n",
        "        input_ids = input_ids + ([pad_token] * padding_length)\n",
        "        input_mask = input_mask + ([0 if mask_padding_with_zero else 1] * padding_length)\n",
        "        segment_ids = segment_ids + ([pad_token_segment_id] * padding_length)\n",
        "\n",
        "        assert len(input_ids) == max_seq_len\n",
        "        assert len(input_mask) == max_seq_len\n",
        "        assert len(segment_ids) == max_seq_len\n",
        "\n",
        "        label_id = label_map[str(example['label'])]\n",
        "\n",
        "        if ex_index < 5:\n",
        "            logger.info(\"*** Example ***\")\n",
        "            # logger.info(\"guid: %s\" % (example.guid))\n",
        "            logger.info(\"tokens: %s\" % \" \".join(\n",
        "                [str(x) for x in tokens]))\n",
        "            logger.info(\"input_ids: %s\" % \" \".join([str(x) for x in input_ids]))\n",
        "            logger.info(\"input_mask: %s\" % \" \".join([str(x) for x in input_mask]))\n",
        "            logger.info(\"segment_ids: %s\" % \" \".join([str(x) for x in segment_ids]))\n",
        "            logger.info(\"label: %s (id = %d)\" % (str(example['label']), label_id))\n",
        "\n",
        "        features.append(\n",
        "            InputFeatures(input_ids=input_ids,\n",
        "                          input_mask=input_mask,\n",
        "                          segment_ids=segment_ids,\n",
        "                          label_id=label_id))\n",
        "    return features\n",
        "\n",
        "  \n",
        "  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-OxQkk9W17zc"
      },
      "source": [
        "train_data:1675034\\\n",
        "val_data:358936\\\n",
        "test_data:358936"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4pOuwVmZCwvi"
      },
      "source": [
        "配置参数"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vo586rf8ustu"
      },
      "outputs": [],
      "source": [
        "config = {\n",
        "    \"model_name_or_path\": \"$pretrained_model\",\n",
        "    \"model_type\": \"roberta\",\n",
        "    \"do_lower_case\": True,\n",
        "    \"tokenizer_name\": \"uer/chinese_roberta_L-12_H-768\",\n",
        "    \"model_name_or_path\": \"$pretrained_model\",\n",
        "    \"max_seq_length\": 256,\n",
        "    \"train_batch_size\": 32,\n",
        "    \"eval_batch_size\": 16,\n",
        "    \"gradient_accumulation_steps\": 1,\n",
        "    \"learning_rate\": 1e-5,\n",
        "    \"weight_decay\": 0.0,\n",
        "    \"adam_epsilon\": 1e-8,\n",
        "    \"max_grad_norm\": 1.0,\n",
        "    \"num_train_epochs\": 4,\n",
        "    \"seed\": 42,\n",
        "    \"data_dir\": \"/content/drive/MyDrive/myclab/codebert/test_data\",\n",
        "    \"no_cuda\": True,\n",
        "    \"output_dir\": \"/content/drive/MyDrive/myclab/codebert/models\",\n",
        "    \"config_name\": \"\",\n",
        "    \"start_step\": \"\",\n",
        "    \"start_epoch\": 0,\n",
        "    \"adam_epsilon\": 1e-8,\n",
        "    \"weight_decay\": 0.0,\n",
        "    \"max_steps\": -1,\n",
        "    \"gradient_accumulation_steps\": 1,\n",
        "    \"warmup_steps\": 0,\n",
        "    \"logging_steps\": 50,\n",
        "    \"evaluate_during_training\": False,\n",
        "    \"local_rank\": -1,\n",
        "    \"task_name\": \"codesearch\", \n",
        "    \"do_eval\": True,\n",
        "    \"pred_model_dir\": \"/content/drive/MyDrive/myclab/codebert/models/checkpoint-best\",\n",
        "    \"test_result_dir\": \"/content/drive/MyDrive/myclab/codebert/result/${idx}_batch_result.txt\",\n",
        "    \"eval_all_checkpoints\": True,\n",
        "\n",
        "}\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NIlcXZd4vQwR"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import os\n",
        "import argparse\n",
        "import random\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import (DataLoader, RandomSampler, SequentialSampler,\n",
        "                              TensorDataset)\n",
        "from transformers import (WEIGHTS_NAME, get_linear_schedule_with_warmup, AdamW,\n",
        "                          RobertaConfig,\n",
        "                          RobertaForSequenceClassification,\n",
        "                          RobertaTokenizer,AutoTokenizer,\n",
        "                          AutoModelForMaskedLM)\n",
        "MODEL_CLASSES = {'roberta': (RobertaConfig, RobertaForSequenceClassification, AutoTokenizer)}\n",
        "\n",
        "\n",
        "def set_seed(args):\n",
        "    random.seed(config[\"seed\"])\n",
        "    np.random.seed(config[\"seed\"])\n",
        "    torch.manual_seed(config[\"seed\"])\n",
        "\n",
        "def load_and_cache_examples(config, processor, tokenizer, ttype='train'):\n",
        "    # if ttype == 'train':\n",
        "    #     file_name = args.train_file.split('.')[0]\n",
        "    # elif ttype == 'dev':\n",
        "    #     file_name = args.dev_file.split('.')[0]\n",
        "    # elif ttype == 'test':\n",
        "    #     file_name = args.test_file.split('.')[0]\n",
        "    # print(\"!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\")\n",
        "    cached_features_file = os.path.join(config['data_dir'], 'cached_{}_{}_{}'.format(\n",
        "        ttype,\n",
        "        list(filter(None, config['model_name_or_path'].split('/'))).pop(),\n",
        "        str(config[\"max_seq_length\"])))\n",
        "\n",
        "    try:\n",
        "        features = torch.load(cached_features_file)\n",
        "        if ttype == 'test':\n",
        "          examples, instances = processor.get_test()\n",
        "    except:\n",
        "        label_list = processor.get_labels()\n",
        "        if ttype == 'train':\n",
        "            examples = processor.get_train()\n",
        "        elif ttype == 'dev':\n",
        "            examples = processor.get_val()\n",
        "        elif ttype == 'test':\n",
        "            examples, instances = processor.get_test()\n",
        "\n",
        "        features = processor.convert_to_feature(examples, config[\"max_seq_length\"], tokenizer)\n",
        "    \n",
        "    all_input_ids = torch.tensor([f.input_ids for f in features], dtype=torch.long)\n",
        "    all_input_mask = torch.tensor([f.input_mask for f in features], dtype=torch.long)\n",
        "    all_segment_ids = torch.tensor([f.segment_ids for f in features], dtype=torch.long)\n",
        "    all_label_ids = torch.tensor([f.label_id for f in features], dtype=torch.long)\n",
        "\n",
        "    # print(all_input_ids.shape)\n",
        "    # print(all_input_mask.shape)\n",
        "    # print(all_segment_ids.shape)\n",
        "    # print(all_label_ids.shape)\n",
        "\n",
        "    dataset = TensorDataset(all_input_ids, all_input_mask, all_segment_ids, all_label_ids)\n",
        "\n",
        "    \n",
        "    if (ttype == 'test'):\n",
        "        return dataset, instances\n",
        "    else:\n",
        "        return dataset\n",
        "\n",
        "\n",
        "\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R7zD5dwuyiRK"
      },
      "outputs": [],
      "source": [
        "pos_data = []\n",
        "neg_data = []\n",
        "for i in range(1):\n",
        "    # pos_path_str = '/content/drive/MyDrive/myclab/codebert/data/data_' + str(i) + '.json'\n",
        "    # neg_path_str = '/content/drive/MyDrive/myclab/codebert/data/negative_data_' + str(i) + '.json'\n",
        "    pos_path_str = '/content/drive/MyDrive/myclab/codebert/data/mixed_pos.json'\n",
        "    neg_path_str = '/content/drive/MyDrive/myclab/codebert/data/mixed_neg.json'\n",
        "    pos_data += json.load(open(pos_path_str, 'r', encoding='utf-8'))\n",
        "    neg_data += json.load(open(neg_path_str, 'r', encoding='utf-8'))\n",
        "\n",
        "processer = DataProcessor(pos_data, neg_data)\n",
        "def train(args, train_dataset, model, tokenizer, optimizer):\n",
        "\n",
        "  if config[\"local_rank\"] in [-1, 0]:\n",
        "    tb_writer = SummaryWriter()\n",
        "\n",
        "  train_sampler = RandomSampler(train_dataset)\n",
        "  train_dataloader = DataLoader(train_dataset, sampler=train_sampler, batch_size=config[\"train_batch_size\"])\n",
        "\n",
        "  if config[\"max_steps\"] > 0:\n",
        "    t_total = config[\"max_steps\"]\n",
        "    config[\"num_train_epochs\"] = config[\"max_steps\"] // (len(train_dataloader) // config[\"gradient_accumulation_steps\"]) + 1\n",
        "  else:\n",
        "    t_total = len(train_dataloader) // config[\"gradient_accumulation_steps\"] * config[\"num_train_epochs\"]\n",
        "\n",
        "  scheduler = get_linear_schedule_with_warmup(optimizer, config[\"warmup_steps\"], t_total)\n",
        "\n",
        "  checkpoint_last = os.path.join(config[\"output_dir\"], 'checkpoint-last')\n",
        "  scheduler_last = os.path.join(checkpoint_last, 'scheduler.pt')\n",
        "  if os.path.exists(scheduler_last):\n",
        "      scheduler.load_state_dict(torch.load(scheduler_last))\n",
        "  \n",
        "  logger.info(\"***** Running training *****\")\n",
        "  logger.info(\"  Num examples = %d\", len(train_dataset))\n",
        "  logger.info(\"  Num Epochs = %d\", config[\"num_train_epochs\"])\n",
        "  logger.info(\"  Instantaneous batch size = %d\", config[\"train_batch_size\"])\n",
        "  # logger.info(\"  Total train batch size (w. parallel, distributed & accumulation) = %d\",\n",
        "  #             config[\"train_batch_size\"] * config[\"gradient_accumulation_steps\"] * (\n",
        "  #                 torch.distributed.get_world_size()))\n",
        "  logger.info(\"  Gradient Accumulation steps = %d\", config[\"gradient_accumulation_steps\"])\n",
        "  logger.info(\"  Total optimization steps = %d\", t_total)\n",
        "\n",
        "  global_step = config[\"start_step\"]\n",
        "  tr_loss, logging_loss = 0.0, 0.0\n",
        "  best_acc = 0.0\n",
        "  model.zero_grad()\n",
        "\n",
        "  train_iterator = trange(config[\"start_epoch\"], int(config[\"num_train_epochs\"]), desc=\"Epoch\")\n",
        "  set_seed(args)\n",
        "  model.train()\n",
        "  for idx, _ in enumerate(train_iterator):\n",
        "    tr_loss = 0.0\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "      # print(len(batch))\n",
        "      batch = tuple(t.to(device) for t in batch)\n",
        "      inputs = {'input_ids': batch[0],\n",
        "            'attention_mask': batch[1],\n",
        "            # 'token_type_ids': batch[2] if args.model_type in ['bert', 'xlnet'] else None,\n",
        "            # # XLM don't use segment_ids\n",
        "            'labels': batch[3]}\n",
        "      ouputs = model(**inputs)\n",
        "      loss = ouputs[0]\n",
        "      print(\"loss: \",loss)\n",
        "      #loss = ouputs[0]\n",
        "\n",
        "      if config[\"gradient_accumulation_steps\"] > 1:\n",
        "        loss = loss / config[\"gradient_accumulation_steps\"]\n",
        "      \n",
        "      loss.backward()\n",
        "      torch.nn.utils.clip_grad_norm_(model.parameters(), config[\"max_grad_norm\"])\n",
        "\n",
        "      tr_loss += loss.item()\n",
        "      if (step + 1) % config[\"gradient_accumulation_steps\"] == 0:\n",
        "        optimizer.step()\n",
        "        scheduler.step()  # Update learning rate schedule\n",
        "        model.zero_grad()\n",
        "        global_step += 1\n",
        "\n",
        "        if config[\"local_rank\"] in [-1, 0] and config[\"logging_steps\"] > 0 and global_step % config[\"logging_steps\"] == 0:\n",
        "          if config[\"evaluate_during_training\"]:\n",
        "              results = evaluate(args, model, tokenizer, checkpoint=str(global_step))\n",
        "              for key, value in results.items():\n",
        "                # tb_writer.add_scalar('eval_{}'.format(key), value, global_step)\n",
        "                logger.info('loss %s', str(tr_loss - logging_loss))\n",
        "          # tb_writer.add_scalar('lr', scheduler.get_lr()[0], global_step)\n",
        "          # tb_writer.add_scalar('loss', (tr_loss - logging_loss) / args.logging_steps, global_step)\n",
        "          logging_loss = tr_loss\n",
        "\n",
        "      if config[\"max_steps\"] > 0 and global_step > config[\"max_steps\"]:\n",
        "        # epoch_iterator.close()\n",
        "        break\n",
        "\n",
        "    if config[\"do_eval\"]:\n",
        "      results = evaluate(args, model, tokenizer, checkpoint=str(config[\"start_epoch\"] + idx))\n",
        "\n",
        "      last_output_dir = os.path.join(config[\"output_dir\"], 'checkpoint-last')\n",
        "      if not os.path.exists(last_output_dir):\n",
        "        os.makedirs(last_output_dir)\n",
        "      model_to_save = model.module if hasattr(model,'module') else model\n",
        "      model_to_save.save_pretrained(last_output_dir)\n",
        "      logger.info(\"Saving model checkpoint to %s\", last_output_dir)\n",
        "      idx_file = os.path.join(last_output_dir, 'idx_file.txt')\n",
        "      with open(idx_file, 'w', encoding='utf-8') as idxf:\n",
        "        idxf.write(str(config[\"start_epoch\"] + idx) + '\\n')\n",
        "\n",
        "      torch.save(optimizer.state_dict(), os.path.join(last_output_dir, \"optimizer.pt\"))\n",
        "      torch.save(scheduler.state_dict(), os.path.join(last_output_dir, \"scheduler.pt\"))\n",
        "      logger.info(\"Saving optimizer and scheduler states to %s\", last_output_dir)\n",
        "\n",
        "      step_file = os.path.join(last_output_dir, 'step_file.txt')\n",
        "      with open(step_file, 'w', encoding='utf-8') as stepf:\n",
        "        stepf.write(str(global_step) + '\\n')\n",
        "\n",
        "      if (results['acc'] > best_acc):\n",
        "        best_acc = results['acc']\n",
        "        output_dir = os.path.join(config[\"output_dir\"], 'checkpoint-best')\n",
        "        if not os.path.exists(output_dir):\n",
        "          os.makedirs(output_dir)\n",
        "          model_to_save = model.module if hasattr(model,'module') else model\n",
        "          model_to_save.save_pretrained(output_dir)\n",
        "          torch.save(args, os.path.join(output_dir, 'training_{}.bin'.format(idx)))\n",
        "          logger.info(\"Saving model checkpoint to %s\", output_dir)\n",
        "\n",
        "          torch.save(optimizer.state_dict(), os.path.join(output_dir, \"optimizer.pt\"))\n",
        "          torch.save(scheduler.state_dict(), os.path.join(output_dir, \"scheduler.pt\"))\n",
        "          logger.info(\"Saving optimizer and scheduler states to %s\", output_dir)\n",
        "    \n",
        "    if config[\"max_steps\"] > 0 and global_step > config[\"max_steps\"]:\n",
        "      train_iterator.close()\n",
        "      break\n",
        "\n",
        "  \n",
        "  return global_step, tr_loss / global_step\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-3kx4Zz_ac7q"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import f1_score\n",
        "def accuracy(out, labels):\n",
        "  outputs = np.argmax(out, axis=1)\n",
        "  return np.sum(outputs == labels)\n",
        "\n",
        "def simple_accuracy(preds, labels):\n",
        "    return (preds == labels).mean()\n",
        "\n",
        "def acc_and_f1(preds, labels):\n",
        "    acc = simple_accuracy(preds, labels)\n",
        "    f1 = f1_score(y_true=labels, y_pred=preds)\n",
        "    return {\n",
        "        \"acc\": acc,\n",
        "        \"f1\": f1,\n",
        "        \"acc_and_f1\": (acc + f1) / 2,\n",
        "    }\n",
        "\n",
        "def compute_metrics(task_name, preds, labels):\n",
        "    assert len(preds) == len(labels)\n",
        "    if task_name == \"codesearch\":\n",
        "        return acc_and_f1(preds, labels)\n",
        "    else:\n",
        "        raise KeyError(task_name)\n",
        "\n",
        "def evaluate(args, model, tokenizer, checkpoint=None, prefix=\"\", mode='dev'):\n",
        "  eval_outputs_dirs = (config[\"output_dir\"],)\n",
        "  eval_task_names = (config[\"task_name\"],)\n",
        "  results = {}\n",
        "  for eval_task, eval_output_dir in zip(eval_task_names, eval_outputs_dirs):\n",
        "    if (mode == 'dev'):\n",
        "      eval_dataset = load_and_cache_examples(args, processer, tokenizer, ttype='dev')\n",
        "    elif (mode == 'test'):\n",
        "      eval_dataset, instances = load_and_cache_examples(args, processer, tokenizer, ttype='test')\n",
        "    \n",
        "    if not os.path.exists(eval_output_dir):\n",
        "      os.makedirs(eval_output_dir)\n",
        "\n",
        "    eval_sampler = SequentialSampler(eval_dataset)\n",
        "    eval_dataloader = DataLoader(eval_dataset, sampler=eval_sampler, batch_size=config[\"eval_batch_size\"])\n",
        "\n",
        "    # Eval!\n",
        "    logger.info(\"***** Running evaluation {} *****\".format(prefix))\n",
        "    logger.info(\"  Num examples = %d\", len(eval_dataset))\n",
        "    logger.info(\"  Batch size = %d\", config[\"eval_batch_size\"])\n",
        "    eval_loss = 0.0\n",
        "    nb_eval_steps = 0\n",
        "    preds = None\n",
        "    out_label_ids = None\n",
        "\n",
        "    for batch in tqdm(eval_dataloader, desc=\"Evaluating\"):\n",
        "      model.eval()\n",
        "      batch = tuple(t.to(device) for t in batch)\n",
        "\n",
        "      with torch.no_grad():\n",
        "        inputs = {'input_ids': batch[0],\n",
        "              'attention_mask': batch[1],\n",
        "              # 'token_type_ids': batch[2],\n",
        "              # XLM don't use segment_ids\n",
        "              'labels': batch[3]}\n",
        "\n",
        "        outputs = model(**inputs)\n",
        "        tmp_eval_loss, logits = outputs[:2]\n",
        "\n",
        "        eval_loss += tmp_eval_loss.mean().item()\n",
        "      \n",
        "      nb_eval_steps += 1\n",
        "      if preds is None:\n",
        "        preds = logits.detach().cpu().numpy()\n",
        "        out_label_ids = inputs['labels'].detach().cpu().numpy()\n",
        "      else:\n",
        "        preds = np.append(preds, logits.detach().cpu().numpy(), axis=0)\n",
        "\n",
        "        out_label_ids = np.append(out_label_ids, inputs['labels'].detach().cpu().numpy(), axis=0)\n",
        "\n",
        "    preds_label = np.argmax(preds, axis=1)\n",
        "    result = compute_metrics(eval_task, preds_label, out_label_ids)\n",
        "    results.update(result)\n",
        "    if (mode == 'dev'):\n",
        "      output_eval_file = os.path.join(eval_output_dir, \"eval_results.txt\")\n",
        "      with open(output_eval_file, \"a+\") as writer:\n",
        "        logger.info(\"***** Eval results {} *****\".format(prefix))\n",
        "        writer.write('evaluate %s\\n' % checkpoint)\n",
        "        for key in sorted(result.keys()):\n",
        "          logger.info(\"  %s = %s\", key, str(result[key]))\n",
        "          writer.write(\"%s = %s\\n\" % (key, str(result[key])))\n",
        "    elif (mode == 'test'):\n",
        "      output_test_file = config[\"test_result_dir\"]\n",
        "      output_dir = os.path.dirname(output_test_file)\n",
        "      if not os.path.exists(output_dir):\n",
        "        os.makedirs(output_dir)\n",
        "      with open(output_test_file, \"w\") as writer:\n",
        "        logger.info(\"***** Output test results *****\")\n",
        "        all_logits = preds.tolist()\n",
        "        for i, logit in tqdm(enumerate(all_logits), desc='Testing'):\n",
        "          instance_rep = '<CODESPLIT>'.join(\n",
        "            [item.encode('utf-8', 'ignore').decode('utf-8') for item in instances[i]])\n",
        "        \n",
        "          writer.write(instance_rep + '<CODESPLIT>' + '<CODESPLIT>'.join([str(l) for l in logit]) + '\\n')\n",
        "        \n",
        "        for key in sorted(result.keys()):\n",
        "          print(\"%s = %s\" % (key, str(result[key])))\n",
        "\n",
        "  return results\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nKrPA4l-yb2-"
      },
      "source": [
        "主程序"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0btjsxoZkXAs",
        "outputId": "97c3e0bc-d351-476e-d3e4-d8ce06077b3a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.dense.bias', 'roberta.pooler.dense.weight', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.weight', 'roberta.pooler.dense.bias', 'lm_head.layer_norm.bias']\n",
            "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "start convert to feature\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1674/1674 [00:04<00:00, 410.80it/s]\n",
            "Epoch: 0it [00:00, ?it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/myclab/codebert/models/checkpoint-best\n",
            "start convert to feature\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/358 [00:00<?, ?it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (669 > 512). Running this sequence through the model will result in indexing errors\n",
            "100%|██████████| 358/358 [00:00<00:00, 1443.62it/s]\n",
            "Evaluating: 100%|██████████| 23/23 [02:02<00:00,  5.31s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/myclab/codebert/models/checkpoint-last\n",
            "start convert to feature\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 358/358 [00:00<00:00, 1648.08it/s]\n",
            "Evaluating: 100%|██████████| 23/23 [02:00<00:00,  5.25s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/myclab/codebert/models\n",
            "start convert to feature\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 358/358 [00:00<00:00, 1719.68it/s]\n",
            "Evaluating: 100%|██████████| 23/23 [02:00<00:00,  5.24s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "testing\n",
            "start convert to feature\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 360/360 [00:00<00:00, 1652.89it/s]\n",
            "Evaluating: 100%|██████████| 23/23 [02:01<00:00,  5.27s/it]\n",
            "Testing: 360it [00:00, 196864.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "acc = 0.49166666666666664\n",
            "acc_and_f1 = 0.5523872445384073\n",
            "f1 = 0.6131078224101479\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'acc': 0.49166666666666664,\n",
              " 'f1': 0.6131078224101479,\n",
              " 'acc_and_f1': 0.5523872445384073}"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ],
      "source": [
        "args = config\n",
        "import glob\n",
        "if args[\"no_cuda\"]:\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() and not args[\"no_cuda\"] else \"cpu\")\n",
        "\n",
        "set_seed(args)\n",
        "\n",
        "\n",
        "\n",
        "label_list = processer.get_labels()\n",
        "num_labels = len(label_list)\n",
        "\n",
        "config[\"start_epoch\"] = 0\n",
        "config[\"start_step\"] = 0\n",
        "\n",
        "checkpoint_last = os.path.join(args[\"output_dir\"], 'checkpoint-last')\n",
        "if os.path.exists(checkpoint_last) and os.listdir(checkpoint_last):\n",
        "    config['model_name_or_path'] = os.path.join(checkpoint_last, 'pytorch_model.bin')\n",
        "    config[\"config_name\"] = os.path.join(checkpoint_last, 'config.json')\n",
        "    idx_file = os.path.join(checkpoint_last, 'idx_file.txt')\n",
        "    with open(idx_file, encoding='utf-8') as idxf:\n",
        "        config[\"start_epoch\"] = int(idxf.readlines()[0].strip()) + 1\n",
        "\n",
        "    step_file = os.path.join(checkpoint_last, 'step_file.txt')\n",
        "    if os.path.exists(step_file):\n",
        "        with open(step_file, encoding='utf-8') as stepf:\n",
        "            config[\"start_step\"] = int(stepf.readlines()[0].strip())\n",
        "\n",
        "config_class, model_class, tokenizer_class = MODEL_CLASSES[config[\"model_type\"]]\n",
        "tokenizer = RobertaTokenizer.from_pretrained('roberta-base', do_lower_case=config[\"do_lower_case\"])\n",
        "model = RobertaForSequenceClassification.from_pretrained('roberta-base')\n",
        "\n",
        "model.to(device)\n",
        "\n",
        "no_decay = ['bias', 'LayerNorm.weight']\n",
        "optimizer_grouped_parameters = [\n",
        "    {'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)],\n",
        "      'weight_decay': config[\"weight_decay\"]},\n",
        "    {'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}]\n",
        "optimizer = AdamW(optimizer_grouped_parameters, lr=config[\"learning_rate\"], eps=config[\"adam_epsilon\"])\n",
        "\n",
        "optimizer_last = os.path.join(checkpoint_last, 'optimizer.pt')\n",
        "if os.path.exists(optimizer_last):\n",
        "    optimizer.load_state_dict(torch.load(optimizer_last))\n",
        "\n",
        "train_dataset = load_and_cache_examples(args, processer, tokenizer, ttype='train')\n",
        "global_step, tr_loss = train(args, train_dataset, model, tokenizer, optimizer)\n",
        "logger.info(\" global_step = %s, average loss = %s\", global_step, tr_loss)\n",
        "\n",
        "if not os.path.exists(config[\"output_dir\"]) and config[\"local_rank\"] in [-1, 0]:\n",
        "  os.makedirs(config[\"output_dir\"])\n",
        "logger.info(\"Saving model checkpoint to %s\", config[\"output_dir\"])\n",
        "model_to_save = model.module if hasattr(model, 'module') else model  # Take care of distributed/parallel training\n",
        "model_to_save.save_pretrained(config[\"output_dir\"])\n",
        "tokenizer.save_pretrained(config[\"output_dir\"])\n",
        "torch.save(args, os.path.join(config[\"output_dir\"], 'training_args.bin'))\n",
        "model = model_class.from_pretrained(config[\"output_dir\"])\n",
        "tokenizer = tokenizer_class.from_pretrained(config[\"output_dir\"])\n",
        "model.to(device)\n",
        "\n",
        "results = {}\n",
        "checkpoints = [config[\"output_dir\"]]\n",
        "if config[\"eval_all_checkpoints\"]:\n",
        "  checkpoints = list(\n",
        "    os.path.dirname(c) for c in sorted(glob.glob(config[\"output_dir\"] + '/**/' + WEIGHTS_NAME, recursive=True)))\n",
        "  logging.getLogger(\"pytorch_transformers.modeling_utils\").setLevel(logging.WARN)  #\n",
        "logger.info(\"Evaluate the following checkpoints: %s\", checkpoints)\n",
        "for checkpoint in checkpoints:\n",
        "  print(checkpoint)\n",
        "  global_step = checkpoint.split('-')[-1] if len(checkpoints) > 1 else \"\"\n",
        "  model = model_class.from_pretrained(checkpoint)\n",
        "  model.to(device)\n",
        "  result = evaluate(args, model, tokenizer, checkpoint=checkpoint, prefix=global_step)\n",
        "  result = dict((k + '_{}'.format(global_step), v) for k, v in result.items())\n",
        "  results.update(result)\n",
        "\n",
        "print('testing')\n",
        "model = model_class.from_pretrained(config[\"pred_model_dir\"])\n",
        "model.to(device)\n",
        "evaluate(args, model, tokenizer, checkpoint=None, prefix='', mode='test')\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "name": "re-codebert",
      "provenance": [],
      "mount_file_id": "1hBFgkNAtp72xGteDOUAlzekz3wb7Gy2q",
      "authorship_tag": "ABX9TyNn+jfQWKpV3n9UKd3ydCE+",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}